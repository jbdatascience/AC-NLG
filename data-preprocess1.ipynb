{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import jieba\n",
    "RESULT_FILE = \"./data/result.txt\"\n",
    "REQUEST_FILE = \"./data/suqiu.txt\"\n",
    "ARTICLE_FILE = \"./data/chaming.txt\"\n",
    "SUMMARRY_FILE = \"./data/renwei_os.txt\"\n",
    "\n",
    "\n",
    "TRAIN_FILE = \"./data/train_art_summ_prep_os.txt\"\n",
    "VAL_FILE = \"./data/val_art_summ_prep_os.txt\\\"\n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        r = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time:\"+ str(cost) +\" s\")\n",
    "        return r\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@timer\n",
    "def load_data(filename):\n",
    "    data_list = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # jieba.enable_parallel()\n",
    "            words = jieba.cut(line.strip())\n",
    "            word_list = list(words)\n",
    "            # jieba.disable_parallel()\n",
    "            data_list.append(' '.join(word_list).strip())\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def build_train_val(results_data, request_data, article_data, summary_data, train_num=8000):\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    n = 0\n",
    "    for results, requests, text, summ in zip(results_data, request_data, article_data, summary_data):\n",
    "        n += 1\n",
    "        if n <= train_num:\n",
    "            train_list.append(results)\n",
    "            train_list.append(requests)\n",
    "            train_list.append(text)\n",
    "            train_list.append(summ)\n",
    "        else:\n",
    "            val_list.append(results)\n",
    "            val_list.append(requests)\n",
    "            val_list.append(text)\n",
    "            val_list.append(summ)\n",
    "    return train_list, val_list\n",
    "\n",
    "\n",
    "def save_file(filename, li):\n",
    "    with open(filename, 'w+', encoding='utf-8') as f:\n",
    "        for item in li:\n",
    "            f.write(item + '\\n')\n",
    "    print(\"Save \"+ filename+ \" ok.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.651 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost time:0.9967644214630127 s\n",
      "Cost time:20.66478180885315 s\n",
      "Cost time:45.17312979698181 s\n",
      "Cost time:52.27590990066528 s\n"
     ]
    }
   ],
   "source": [
    "result_data = load_data(RESULT_FILE)\n",
    "request_data = load_data(REQUEST_FILE)\n",
    "article_data = load_data(ARTICLE_FILE)  # 大概耗时10分钟\n",
    "summary_data = load_data(SUMMARRY_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61670\n",
      "61670\n",
      "61670\n",
      "61670\n",
      "53331\n"
     ]
    }
   ],
   "source": [
    "print(len(result_data))\n",
    "print(len(request_data))\n",
    "print(len(article_data))\n",
    "print(len(summary_data))\n",
    "TRAIN_SPLIT = 53331\n",
    "\n",
    "train_list, val_list = build_train_val(result_data, request_data, article_data, summary_data, train_num=TRAIN_SPLIT)\n",
    "\n",
    "print(TRAIN_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save ./data/datav4/train_art_summ_prep_os.txt ok.\n",
      "Save ./data/datav4/val_art_summ_prep_os.txt ok.\n"
     ]
    }
   ],
   "source": [
    "save_file(TRAIN_FILE, train_list)\n",
    "save_file(VAL_FILE, val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
